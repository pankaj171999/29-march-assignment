{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d6d3e1-92f1-43ad-ab6c-fe17551bcef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1(Ans)This is a regularization technique used in feature selection using a Shrinkage method also referred to as the penalized regression method. \n",
    "Lasso is short for Least Absolute Shrinkage and Selection Operator, which is used both for regularization and model selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0494d537-a386-4dba-a71a-9d3ab5f3f267",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q2(Ans) \n",
    "*It helps to prevent overfitting and improve the model's generalization performance.\n",
    "*It provides greater prediction accuracy as compared to other regression models. \n",
    "*Lasso Regularization helps to increase model interpretation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "118ed872-8483-4b9d-9268-3384997d4101",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q3(Ans)What does Lasso regression do to coefficients?\n",
    "Lasso regression uses shrinkage, where the data values are shrunk towards a central point such as the mean value. \n",
    "The Lasso penalty shrinks or reduces the coefficient value towards zero. The less contributing variable is therefore allowed to have a zero or near-zero coefficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9806a0d9-e67d-4bd5-a7af-6f439bb04de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q4(Ans)A tuning parameter (Î»), sometimes called a penalty parameter, controls the strength of the penalty term in ridge regression and lasso regression. \n",
    "It is basically the amount of shrinkage, where data values are shrunk towards a central point, like the mean.\n",
    "\n",
    "LASSO (L1) regularization penalizes the absolute sum of weights. Consequently, many weights are set equal to 0.\n",
    "LASSO is useful to select salient features out of large sets and create simpler models, but also may drastically reduce predictive power."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82fb88aa-2ac1-4e31-bd70-8032aade24a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q5(Ans) Lasso Regression cannot used for non-linear regression problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "928ef8db-1f0e-48d8-9644-f8def99c8c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q6(Ans)Ridge regression shrinks the coefficients towards zero, while Lasso regression encourages some of them to be exactly zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a036c9a6-a588-4914-b936-a6f1e5c4cd3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q7(Ans)LASSO regression is useful when you have some multicollinearity in your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8cfa47c-0438-4f71-ae9b-d29a8ef6cadc",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q8(Ans)The best cross-validation score is obtained for the 0.4 value of lambda. This is your optimal value of lambda.\n",
    "When choosing a lambda value, the goal is to strike the right balance between simplicity and training-data fit: \n",
    "If your lambda value is too high, your model will be simple, but you run the risk of underfitting your data. Your model cannot learn enough about the training data to make useful predictions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
